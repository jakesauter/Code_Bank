{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/sauterj1/Documents/Patient_Folder_Analysis/Python/')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import pprint\n",
    "import ccl_bplist\n",
    "\n",
    "\n",
    "def parse_pop_info_for_flow_dir(flow_directory): \n",
    "  \n",
    "  populations = ['CD34+', 'WBC', 'CD117', 'B cells', 'Lymphocytes', \n",
    "               'Eryhthroids', 'Singlets', 'Plasma cells', 'Granulocytes', \n",
    "               'WBC', 'Monocytes', 'Basophils', 'Eosynophils', 'PCDC']\n",
    "  \n",
    "  owd = os.getcwd()\n",
    "  os.chdir(flow_directory)\n",
    "  flow_directory_files = os.listdir(flow_directory)\n",
    "  nlys_files = [file for file in flow_directory_files if file.endswith(\".nlys\")]\n",
    "  \n",
    "  if len(nlys_files) > 1: \n",
    "    print(\"MORE THAN ONE NLYS FILE FOUND, PROCEDING WITH: \" + nlys_files[0])\n",
    "    \n",
    "  nlys_filename = nlys_files[0]\n",
    "  xml_filename = nlys_filename.split('.')[0] + '.xml'\n",
    "  \n",
    "  os.system('plutil -convert xml1 -o \"' + xml_filename + '\" ' + '\"' + nlys_filename +  '\"')\n",
    "  \n",
    "  plist = ccl_bplist.load(open(nlys_filename, 'rb'))\n",
    "  object_table = plist['$objects']\n",
    "\n",
    "  xml_file = open(xml_filename, 'r')\n",
    "  xml_lines = xml_file.readlines() \n",
    "\n",
    "  # Now filter these lines for lines that the next line contains \"<integer>\"\n",
    "  number_lines = [\":Number\" in line for line in xml_lines]\n",
    "  number_line_idxs =  [i for i, x in enumerate(number_lines) if x]\n",
    "\n",
    "  # Considering whether the line after OR second line after are integer lines\n",
    "  pop_number_lines = [x for x in number_line_idxs if '<integer>' in xml_lines[x+1] or '<integer>' in xml_lines[x+2]]\n",
    "  pop_number_strings = [re.search('>.*:', xml_lines[i]).group(0)[1:-1] for i in pop_number_lines]\n",
    "\n",
    "  # Have to choose one line or the other\n",
    "  pop_nums = []\n",
    "  for i in pop_number_lines: \n",
    "    pop_num_1 = re.search('integer>.*<', xml_lines[i+1])\n",
    "    pop_num_2 = re.search('integer>.*<', xml_lines[i+2])\n",
    "\n",
    "    if pop_num_1 is None: \n",
    "      pop_num = pop_num_2.group(0)[8:-1]\n",
    "    else: \n",
    "      pop_num = pop_num_1.group(0)[8:-1]\n",
    "\n",
    "    pop_nums.append(pop_num)\n",
    "\n",
    "  filename_pop_number_loc_dict = {}\n",
    "  \n",
    "  filename_in_lines = [re.search('<string>.*\\.fcs</string>', line) is not None for line in xml_lines]\n",
    "  filename_line_idxs = [i for i, x in enumerate(filename_in_lines) if x]\n",
    "  filename_lines = [xml_lines[i] for i in filename_line_idxs]\n",
    "  filenames = [re.search('>.*<', filename_line).group(0)[1:-1] for filename_line in filename_lines]\n",
    "\n",
    "  for pop_number_line_idx in pop_number_lines: \n",
    "    assoc_filename_line = max(filter(lambda filename_line_idx: filename_line_idx < pop_number_line_idx, filename_line_idxs))\n",
    "    filename = filenames[filename_line_idxs.index(assoc_filename_line)]\n",
    "    filename_pop_number_loc_dict[pop_number_line_idx] = filename\n",
    "\n",
    "  pop_number_dict = {}\n",
    "\n",
    "  for i in range(len(pop_nums)):\n",
    "    line_idx = pop_number_lines[i]\n",
    "    filename = filename_pop_number_loc_dict[line_idx]\n",
    "    if filename not in pop_number_dict: \n",
    "      pop_number_dict[filename] = {pop_number_strings[i]: int(pop_nums[i])}\n",
    "    else: \n",
    "      pop_number_dict[filename][pop_number_strings[i]] = int(pop_nums[i])\n",
    "      \n",
    "  # Resolve unfound populations\n",
    "  pop_num_dict_keys = list(pop_number_dict.keys())\n",
    "  found_keys = list(pop_number_dict[pop_num_dict_keys[0]].keys()) + \\\n",
    "               list(pop_number_dict[pop_num_dict_keys[1]].keys())\n",
    "\n",
    "  for population in populations: \n",
    "    if population not in found_keys: \n",
    "      number_lines = [population + \":Number\" in line for line in xml_lines]\n",
    "      number_line_idx =  [i for i, x in enumerate(number_lines) if x][0]\n",
    "      ## TODO: Could make this more robust by searching for last ANValue tag\n",
    "      pop_number_string =  re.search('integer>.*<', xml_lines[number_line_idx-3])\n",
    "      try: \n",
    "        pop_uid = int(pop_number_string.group(0)[8:-1])\n",
    "        pop_num = object_table[pop_uid]\n",
    "        # Figure out which M1/M2 it belongs to \n",
    "        assoc_filename_line = max(filter(lambda filename_line_idx: filename_line_idx < number_line_idx, filename_line_idxs))\n",
    "        filename = filenames[filename_line_idxs.index(assoc_filename_line)]\n",
    "        pop_number_dict[filename][population] = int(pop_num)\n",
    "      except: \n",
    "        pass\n",
    "      \n",
    "  simplified_pop_number_dict = {}\n",
    "\n",
    "  for k,v in pop_number_dict.items():\n",
    "    key = re.search(\"m1|m2\", k, re.IGNORECASE)\n",
    "    if key is None: continue\n",
    "    simplified_pop_number_dict[key.group(0).upper()] = pop_number_dict[k]\n",
    "    \n",
    "  # change back to orignal working directory\n",
    "  os.chdir(owd)\n",
    "            \n",
    "  return(simplified_pop_number_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \"/Users/sauterj1/Documents/Woodlist/Flow_Folders\"\n",
    "flow_directories = os.listdir(flow_path)\n",
    "flow_directories = [os.path.join(flow_path, x) for x in flow_directories]\n",
    "flow_directories = [x for x in flow_directories if os.path.isdir(x)]\n",
    "                    \n",
    "flow_directories[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dict_list = [{}] * len(flow_directories)\n",
    "\n",
    "for i in range(len(flow_directories)): \n",
    "  pop_num_dict = parse_pop_info_for_flow_dir(flow_directories[i])\n",
    "\n",
    "  #compress the dictionary into one\n",
    "  flat_dict = {}\n",
    "\n",
    "  for tube in pop_num_dict.keys(): \n",
    "    for pop_name in pop_num_dict[tube].keys(): \n",
    "      key = tube + '_' + pop_name\n",
    "      flat_dict[key] = pop_num_dict[tube][pop_name]\n",
    "      \n",
    "  flat_dict['flow_folder'] = os.path.basename(flow_directories[i])\n",
    "    \n",
    "  flat_dict_list[i] = flat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_key_dict = {}\n",
    "\n",
    "for flat_dict in flat_dict_list: \n",
    "  for key in flat_dict.keys(): \n",
    "    if key not in unique_key_dict.keys():\n",
    "      unique_key_dict[key] = 1\n",
    "      \n",
    "for flat_dict in flat_dict_list: \n",
    "  for key in unique_key_dict.keys():\n",
    "    if key not in flat_dict.keys():\n",
    "      flat_dict[key] = -100\n",
    "      \n",
    "# merge into one dict\n",
    "flat_dict_list[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "keys = flat_dict_list[0].keys()\n",
    "\n",
    "with open('/Users/sauterj1/Desktop/cohort_cell_pop_info.csv', 'w', newline='')  as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(flat_dict_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
